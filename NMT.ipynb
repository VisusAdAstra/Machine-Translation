{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, layers, models\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.attention as attention\n",
    "importlib.reload(attention);\n",
    "import src.models as model\n",
    "importlib.reload(model)\n",
    "import src.utils as util\n",
    "importlib.reload(util);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-word mapping\n",
    "target_vocab_size_en = 400\n",
    "target_vocab_size_fr = 600\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    f\" --input=data/small_vocab_en --model_type=unigram --hard_vocab_limit=false\" +\n",
    "    f\" --model_prefix=data/en --vocab_size={target_vocab_size_en}\")\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    f\" --input=data/small_vocab_fr --model_type=unigram --hard_vocab_limit=false\" +\n",
    "    f\" --model_prefix=data/fr --vocab_size={target_vocab_size_fr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global data\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_en.Load(os.path.join(\"data\", 'en.model'))\n",
    "\n",
    "sp_fr = spm.SentencePieceProcessor()\n",
    "sp_fr.Load(os.path.join(\"data\", 'fr.model'))\n",
    "\n",
    "\n",
    "file = open(os.path.join('data', 'small_vocab_en'), 'r', encoding='utf-8')\n",
    "en_text = file.read().split(\"\\n\")\n",
    "file = open(os.path.join('data', 'small_vocab_fr'), 'r', encoding='utf-8')\n",
    "fr_text = file.read().split(\"\\n\")\n",
    "\n",
    "train_en_X = []\n",
    "train_fr_X = []\n",
    "train_fr_Y = []\n",
    "\n",
    "en_max_len = 0\n",
    "fr_max_len = 0\n",
    "\n",
    "vocab_size_en = sp_en.GetPieceSize() #-1\n",
    "vocab_size_fr = sp_fr.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_bert(text):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "\n",
    "# source_tokenizer = [tokenize_bert(ele) for ele in source]\n",
    "# source_tensor = source_tokenizer\n",
    "# print(source_tokenizer[0])\n",
    "\n",
    "# target_tokenizer = [tokenize_bert(ele) for ele in target]\n",
    "# target_tensor = target_tokenizer\n",
    "# print(target_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(source_tensor, target_tensor, test_size=0.2, random_state=0)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "\n",
    "# Show length\n",
    "# print(len(X_train), len(y_train), len(X_val), len(y_val))\n",
    "# type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the source and target tokens and post pad them\n",
    "# Assuming three extra tokens: <end>: #vocab_size_en | #vocab_size_fr,\n",
    "# <empty>: #vocab_size_en+1 | #vocab_size_fr+1, and <start>: #vocab_size_fr+2\n",
    "\n",
    "end_token_id_en = vocab_size_en\n",
    "empty_token_id_en = vocab_size_en + 1\n",
    "end_token_id_fr = vocab_size_fr\n",
    "empty_token_id_fr = vocab_size_fr + 1\n",
    "start_token_id_fr = vocab_size_fr + 2\n",
    "\n",
    "# The input text only needs two extra tokens while the output needs 3\n",
    "vocab_size_en = vocab_size_en + 2\n",
    "vocab_size_fr = vocab_size_fr + 3\n",
    "\n",
    "\n",
    "for i in range(len(en_text)):\n",
    "  en_seq = sp_en.EncodeAsIds(en_text[i].strip()) + [end_token_id_en]\n",
    "  en_max_len = max(en_max_len, len(en_seq))\n",
    "  train_en_X.append(en_seq)\n",
    "\n",
    "  fr_seq = sp_fr.EncodeAsIds(fr_text[i].strip()) + [end_token_id_fr]\n",
    "  fr_max_len = max(fr_max_len, len(fr_seq))\n",
    "  train_fr_X.append(fr_seq)\n",
    "\n",
    "# Cleaning up the memory, work with subword\n",
    "en_text = []\n",
    "fr_text = []\n",
    "\n",
    "# Padding all the samples with <empty> token to make them all of the same length\n",
    "# equal to the longest one\n",
    "train_en_X = pad_sequences(train_en_X, maxlen=en_max_len,\n",
    "                           padding=\"post\", value=empty_token_id_en)\n",
    "# maxlen is fr_max_len+1 since we need to accomodate for <start>\n",
    "train_fr_X = pad_sequences(train_fr_X, maxlen=fr_max_len+1,\n",
    "                           padding=\"post\", value=empty_token_id_fr)\n",
    "\n",
    "# Converting the train_fr_Y to a one-hot vector needed by the training phase as\n",
    "# the output\n",
    "train_fr_Y = to_categorical(train_fr_X, num_classes=vocab_size_fr)\n",
    "\n",
    "# Moving the last <empty> to the first position in each input sample\n",
    "train_fr_X = np.roll(train_fr_X, 1, axis=-1)\n",
    "# Changing the first token in each input sample to <start>\n",
    "train_fr_X[:, 0] = start_token_id_fr\n",
    "\n",
    "fr_max_len = fr_max_len + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Input Language; index to word mapping\")\n",
    "# util.convert(source_tokenizer, X_train[0])\n",
    "# print ()\n",
    "# print (\"Target Language; index to word mapping\")\n",
    "# util.convert(target_tokenizer, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder input (English)\n",
    "hidden_dim = 128\n",
    "input_en = Input(batch_shape=(None, en_max_len), name='input_en')\n",
    "\n",
    "# English embedding layer\n",
    "embedding_en = layers.Embedding(vocab_size_en, hidden_dim, name='embedding_en')\n",
    "embedded_en = embedding_en(input_en)\n",
    "\n",
    "# Encoder RNN (LSTM) layer\n",
    "encoder_lstm = layers.Bidirectional(\n",
    "                  layers.LSTM(hidden_dim,\n",
    "                              return_sequences=True, return_state=True),\n",
    "                  name=\"encoder_lstm\")\n",
    "(encoded_en,\n",
    "  forward_h_en, forward_c_en,\n",
    "  backward_h_en, backward_c_en) = encoder_lstm(embedded_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder input (French)\n",
    "input_fr = Input(batch_shape=(None, None), name='input_fr')\n",
    "\n",
    "# English embedding layer\n",
    "embedding_fr = layers.Embedding(vocab_size_fr, hidden_dim, name='embedding_fr')\n",
    "embedded_fr = embedding_fr(input_fr)\n",
    "\n",
    "state_h_en = layers.concatenate([forward_h_en, backward_h_en])\n",
    "state_c_en = layers.concatenate([forward_c_en, backward_c_en])\n",
    "\n",
    "# Decoder RNN (LSTM) layer\n",
    "decoder_lstm = layers.LSTM(hidden_dim * 2, return_sequences=True,\n",
    "                           return_state=True, name=\"decoder_lstm\")\n",
    "(encoded_fr,\n",
    "  forward_h_fr, forward_c_fr) = decoder_lstm(embedded_fr,\n",
    "                 initial_state=[state_h_en, state_c_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention layer\n",
    "attention_layer = attention.AttentionLayer(name='attention_layer')\n",
    "attention_out, attention_states = attention_layer({\"values\": encoded_en,\n",
    "                                                   \"query\": encoded_fr})\n",
    "\n",
    "# Concatenating the decoder output with attention output\n",
    "rnn_output = layers.concatenate([encoded_fr, attention_out], name=\"rnn_output\")\n",
    "\n",
    "# Dense layer\n",
    "dense_layer0 = layers.Dense(2048, activation='relu', name='dense_0')\n",
    "dl0 = dense_layer0(rnn_output)\n",
    "\n",
    "dense_layer1 = layers.Dense(1024, activation='relu', name='dense_1')\n",
    "dl1 = dense_layer1(dl0)\n",
    "\n",
    "dense_layer2 = layers.Dense(512, activation='relu', name='dense_2')\n",
    "dl2 = dense_layer2(dl1)\n",
    "\n",
    "dl2 = layers.Dropout(0.4)(dl2)\n",
    "\n",
    "dense_layer3 = layers.Dense(vocab_size_fr, activation='softmax', name='dense_3')\n",
    "dense_output = dense_layer3(dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_en (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_en (Embedding)        (None, 50, 128)      44672       input_en[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_fr (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (Bidirectional)    [(None, 50, 256), (N 263168      embedding_en[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_fr (Embedding)        (None, None, 128)    65024       input_fr[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][3]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           encoder_lstm[0][2]               \n",
      "                                                                 encoder_lstm[0][4]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  394240      embedding_fr[0][0]               \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      decoder_lstm[0][0]               \n",
      "                                                                 encoder_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "rnn_output (Concatenate)        (None, None, 512)    0           decoder_lstm[0][0]               \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, None, 2048)   1050624     rnn_output[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 1024)   2098176     dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 512)    524800      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 512)    0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 508)    260604      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,832,636\n",
      "Trainable params: 4,832,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_en (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_en (Embedding)        (None, 50, 128)      44672       input_en[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (Bidirectional)    [(None, 50, 256), (N 263168      embedding_en[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][3]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           encoder_lstm[0][2]               \n",
      "                                                                 encoder_lstm[0][4]               \n",
      "==================================================================================================\n",
      "Total params: 307,840\n",
      "Trainable params: 307,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_fr (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_fr (Embedding)        (None, None, 128)    65024       input_fr[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_h (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_c (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  394240      embedding_fr[0][0]               \n",
      "                                                                 input_h[0][0]                    \n",
      "                                                                 input_c[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_encoded_en (InputLayer)   [(None, 50, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      decoder_lstm[1][0]               \n",
      "                                                                 input_encoded_en[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "generative_output (Concatenate) (None, None, 512)    0           decoder_lstm[1][0]               \n",
      "                                                                 attention_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, None, 2048)   1050624     generative_output[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 1024)   2098176     dense_0[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 512)    524800      dense_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 508)    260604      dense_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,524,796\n",
      "Trainable params: 4,524,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "training_model = models.Model([input_en, input_fr], dense_output)\n",
    "training_model.summary()\n",
    "\n",
    "training_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=[model.MaskedCategoricalAccuracy(empty_token_id_fr),\n",
    "                                model.ExactMatchedAccuracy(empty_token_id_fr)])\n",
    "\n",
    "# Generative models\n",
    "encoder_model = models.Model([input_en],\n",
    "                             [encoded_en,\n",
    "                              state_h_en, state_c_en])\n",
    "encoder_model.summary()\n",
    "\n",
    "\n",
    "# The decoder model, to generate the French tokens (in integer form)\n",
    "input_h = layers.Input(batch_shape=(None, hidden_dim * 2),\n",
    "                       name='input_h')\n",
    "input_c = layers.Input(batch_shape=(None, hidden_dim * 2),\n",
    "                       name='input_c')\n",
    "\n",
    "(decoder_output,\n",
    "  output_h,\n",
    "  output_c) = decoder_lstm(embedded_fr,\n",
    "                           initial_state=[input_h, input_c])\n",
    "\n",
    "input_encoded_en = layers.Input(batch_shape=(None, en_max_len, hidden_dim * 2),\n",
    "                                name='input_encoded_en')\n",
    "\n",
    "attention_out, attention_state = attention_layer({\"values\": input_encoded_en,\n",
    "                                                  \"query\": decoder_output})\n",
    "\n",
    "generative_output = layers.concatenate([decoder_output,\n",
    "                                        attention_out],\n",
    "                                       name=\"generative_output\")\n",
    "\n",
    "g0 = dense_layer0(generative_output)\n",
    "g1 = dense_layer1(g0)\n",
    "g2 = dense_layer2(g1)\n",
    "dense_output = dense_layer3(g2)\n",
    "\n",
    "decoder_model = models.Model([input_encoded_en, input_fr,\n",
    "                              input_h, input_c],\n",
    "                             [dense_output, attention_state,\n",
    "                              output_h, output_c])\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\nNum GPUs Available:  1\ntf.Tensor(\n[[22. 28.]\n [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "with tf.device('/g:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "# Runs the op.\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "  1/123 [..............................] - ETA: 21:58 - loss: 6.2326 - masked_categorical_accuracy: 0.0026 - exact_matched_accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "checkpoint_dir = 'save'\n",
    "\n",
    "pocket = EarlyStopping(monitor='val_exact_matched_accuracy', min_delta=0.001,\n",
    "                       patience=10, verbose=1, mode='max',\n",
    "                       restore_best_weights = True)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    history = training_model.fit(x=[train_en_X, train_fr_X], y=train_fr_Y, batch_size=786,\n",
    "                             epochs=100, verbose=1, validation_split=0.3, shuffle=True,\n",
    "                             workers=5, use_multiprocessing=True, callbacks=[pocket])\n",
    "\n",
    "training_model.save_weights(os.path.join(checkpoint_dir, \"nmt.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'save'\n",
    "#training_model.save_weights(os.path.join(checkpoint_dir, \"nmt.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring the latest checkpoint in checkpoint_dir\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "training_model.load_weights(os.path.join(checkpoint_dir, \"nmt.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "#util.plot_training(history)\n",
    "\n",
    "results = training_model.evaluate(x=[train_en_X, train_fr_X], y=train_fr_Y,\n",
    "                                  batch_size=786, verbose=1,\n",
    "                                  workers=1, use_multiprocessing=False)\n",
    "\n",
    "print('Test loss:', results[0])\n",
    "print('Test masked categorical accuracy:', results[1])\n",
    "print('Test exact matched accuracy:', results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# The input English string\n",
    "english_string = \"the united states is never freezing during november , but the a51 is sometimes rainy in winter .\"\n",
    "\n",
    "# First, let's tokenize the Eglish string, then pad it\n",
    "english_tokens = sp_en.EncodeAsIds(english_string.strip()) + [end_token_id_en]\n",
    "english_tokens = pad_sequences([english_tokens], maxlen=en_max_len,\n",
    "                               padding=\"post\", value=empty_token_id_en)\n",
    "\n",
    "# The encoder, we only need to use it once per each English string\n",
    "(encoded_en_test,\n",
    "  state_h_en_test, state_c_en_test) = encoder_model.predict(english_tokens)\n",
    "\n",
    "# In order to find a better translation, we are using Beam search\n",
    "beam_search_list = [{\n",
    "  \"decoder_input\": {\n",
    "    \"input_encoded_en\": encoded_en_test,\n",
    "    \"input_fr\": np.array([[start_token_id_fr]]),\n",
    "    \"input_h\": state_h_en_test,\n",
    "    \"input_c\": state_c_en_test\n",
    "  },\n",
    "  \"score\": 0.0,\n",
    "  \"parent_node\": None,\n",
    "  \"depth\": 0,\n",
    "  \"attention_weights\": None,\n",
    "}]\n",
    "ended_branches = []\n",
    "\n",
    "beam_size = 10\n",
    "\n",
    "# We are generating up to fr_max_len tokens\n",
    "for i in range(fr_max_len):\n",
    "  new_beam_candidates = []\n",
    "  # Predict the next token for each member of the list\n",
    "  for beam in beam_search_list:\n",
    "    # Use the decoder to predict the next token using the previously\n",
    "    # predicted token\n",
    "    (output,\n",
    "      attention_out,\n",
    "      state_h_en_test,\n",
    "      state_c_en_test) = decoder_model.predict(beam[\"decoder_input\"])\n",
    "    # Find the top beam_size candidates\n",
    "    top_k = np.argpartition(output[0, 0, :], -beam_size)[-beam_size:]\n",
    "    # For each candidate, put it in the list to predict the next token for it\n",
    "    for k in top_k:\n",
    "      if output[0, 0, k].item() > 0.0:\n",
    "        log_k = math.log(output[0, 0, k].item())\n",
    "      else:\n",
    "        log_k = -sys.float_info.max\n",
    "\n",
    "      if k == end_token_id_fr:\n",
    "        ended_branches.append({\n",
    "          \"decoder_input\": {\n",
    "            \"input_encoded_en\": encoded_en_test,\n",
    "            \"input_fr\": np.array([[k]]),\n",
    "            \"input_h\": state_h_en_test,\n",
    "            \"input_c\": state_c_en_test,\n",
    "          },\n",
    "          \"score\": beam[\"score\"] + log_k,\n",
    "          \"parent_node\": beam,\n",
    "          \"depth\": beam[\"depth\"] + 1,\n",
    "          \"attention_weights\": attention_out,\n",
    "        })\n",
    "      else:\n",
    "        new_beam_candidates.append({\n",
    "          \"decoder_input\": {\n",
    "            \"input_encoded_en\": encoded_en_test,\n",
    "            \"input_fr\": np.array([[k]]),\n",
    "            \"input_h\": state_h_en_test,\n",
    "            \"input_c\": state_c_en_test,\n",
    "          },\n",
    "          \"score\": beam[\"score\"] + log_k,\n",
    "          \"parent_node\": beam,\n",
    "          \"depth\": beam[\"depth\"] + 1,\n",
    "          \"attention_weights\": attention_out,\n",
    "        })\n",
    "\n",
    "  # Keeping only the top beam_size in the list\n",
    "  beam_search_list = sorted(new_beam_candidates,\n",
    "                            key=lambda b: b[\"score\"],\n",
    "                            reverse=True)[0:beam_size]\n",
    "\n",
    "# Now that we are done with our beam search, let's take the best score and\n",
    "# detokenize it\n",
    "beam_node = sorted(beam_search_list + ended_branches,\n",
    "                   key=lambda b: b[\"score\"] / b[\"depth\"],\n",
    "                   reverse=True)[0]\n",
    "\n",
    "# Trace the best beam back to the parent node\n",
    "all_french_tokens = []\n",
    "attention_weights = []\n",
    "while beam_node[\"parent_node\"] is not None:\n",
    "    all_french_tokens.append(\n",
    "        beam_node[\"decoder_input\"][\"input_fr\"][0, 0].item())\n",
    "    attention_weights.append(beam_node[\"attention_weights\"])\n",
    "    beam_node = beam_node[\"parent_node\"]\n",
    "\n",
    "# We traced from tail to head, so we need to reserve the order to have it the right way\n",
    "all_french_tokens.reverse()\n",
    "attention_weights.reverse()\n",
    "\n",
    "# If there's any token out of the vocab, exclude it. This includes `<end>`,\n",
    "# `<empty>`, and <start> tokens\n",
    "french_tokens = [t for t in all_french_tokens if t < sp_fr.get_piece_size()]\n",
    "\n",
    "# Voila!\n",
    "french_string = sp_fr.DecodeIds(french_tokens)\n",
    "\n",
    "print(\"The input English string: \", english_string)\n",
    "print(\"The output French string: \", french_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the alignment matrix\n",
    "attention_mat = []\n",
    "for attn in attention_weights:\n",
    "  attention_mat.append(attn.reshape(-1))\n",
    "\n",
    "# We want to have the English tokens on the left axis, so we need to\n",
    "# trasponse the matrix over the diagonal running from upper right to lower left\n",
    "attention_mat = np.flipud(np.transpose(np.flipud(attention_mat)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "ax.imshow(attention_mat)\n",
    "\n",
    "ax.set_xticks(np.arange(attention_mat.shape[1]))\n",
    "ax.set_yticks(np.arange(attention_mat.shape[0]))\n",
    "\n",
    "def map_en_special_tokens(t):\n",
    "    switcher = {}\n",
    "    switcher[end_token_id_en] = \"<end>\"\n",
    "    switcher[empty_token_id_en] = \"<empty>\"\n",
    "    return switcher.get(t, \"<unknown>\")\n",
    "\n",
    "def map_fr_special_tokens(t):\n",
    "    switcher = {}\n",
    "    switcher[end_token_id_fr] = \"<end>\"\n",
    "    switcher[empty_token_id_fr] = \"<empty>\"\n",
    "    switcher[start_token_id_fr] = \"<start>\"\n",
    "    return switcher.get(t, \"<unknown>\")\n",
    "\n",
    "ax.set_xticklabels([sp_fr.IdToPiece(t)\n",
    "                    if t < sp_fr.get_piece_size() else map_fr_special_tokens(t)\n",
    "                    for t in all_french_tokens])\n",
    "ax.set_yticklabels([sp_en.IdToPiece(t)\n",
    "                    if t < sp_en.get_piece_size() else map_en_special_tokens(t)\n",
    "                    for t in english_tokens[0].tolist()])\n",
    "\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# translate(u'I am going to work.')\n",
    "# translate(u'The project is super hard.')\n",
    "# util.translate(u'She works at home.', units, max_target_length, max_source_length, encoder, decoder, source_tokenizer, target_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "history = []\n",
    "\n",
    "with open('stat.txt', 'r') as f:\n",
    "    csv_f = csv.reader(f, delimiter=',')\n",
    "    \n",
    "    for row in csv_f:\n",
    "        history.append([float(row[1]), float(row[3]), float(row[5]), float(row[7]), float(row[9]), float(row[11]), float(row[13])])\n",
    "\n",
    "history = np.array(history)\n",
    "util.plot_training2(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Default GPU device: /device:GPU:0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "422/422 [==============================] - 3s 5ms/step - loss: 0.6368 - accuracy: 0.8050 - val_loss: 0.0534 - val_accuracy: 0.9863\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0839 - accuracy: 0.9740 - val_loss: 0.0440 - val_accuracy: 0.9890\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0598 - accuracy: 0.9814 - val_loss: 0.0360 - val_accuracy: 0.9912\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.0317 - val_accuracy: 0.9918\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 0.0302 - val_accuracy: 0.9920\n",
      "Time taken to execute:0:00:10.686429\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "if not tf.test.gpu_device_name(): \n",
    "    warnings.warn('No GPU found')\n",
    "else: \n",
    "    print('Default GPU device: {}' .format(tf.test.gpu_device_name()))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Import all required libraries\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "# Split MNIST Train and Test data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Divide train set by 255\n",
    "x_train, x_test = x_train.astype(\"float32\") / 255, x_test.astype(\"float32\") / 255\n",
    "x_train, x_test = np.expand_dims(x_train, -1), np.expand_dims(x_test, -1)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train, y_test = keras.utils.to_categorical(y_train, num_classes=10), keras.utils.to_categorical(y_test, num_classes=10)\n",
    "# Build the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28,28,1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(1, 1)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "# Model summary and Evaluation\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "start = datetime.now()\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.1)\n",
    "stop = datetime.now()\n",
    "print(\"Time taken to execute:\" + str(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH,IMAGE_HEIGHT,3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "images = np.zeros((BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n",
    "labels = np.zeros((BATCH_SIZE, 4))\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(images, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}