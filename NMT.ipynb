{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, layers, models\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.attention as attention\n",
    "importlib.reload(attention);\n",
    "import src.models as model\n",
    "importlib.reload(model)\n",
    "import src.utils as util\n",
    "importlib.reload(util);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-word mapping\n",
    "target_vocab_size_en = 400\n",
    "target_vocab_size_fr = 600\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    f\" --input=data/small_vocab_en --model_type=unigram --hard_vocab_limit=false\" +\n",
    "    f\" --model_prefix=data/en --vocab_size={target_vocab_size_en}\")\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    f\" --input=data/small_vocab_fr --model_type=unigram --hard_vocab_limit=false\" +\n",
    "    f\" --model_prefix=data/fr --vocab_size={target_vocab_size_fr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global data\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_en.Load(os.path.join(\"data\", 'en.model'))\n",
    "\n",
    "sp_fr = spm.SentencePieceProcessor()\n",
    "sp_fr.Load(os.path.join(\"data\", 'fr.model'))\n",
    "\n",
    "\n",
    "file = open(os.path.join('data', 'small_vocab_en'), 'r', encoding='utf-8')\n",
    "en_text = file.read().split(\"\\n\")\n",
    "file = open(os.path.join('data', 'small_vocab_fr'), 'r', encoding='utf-8')\n",
    "fr_text = file.read().split(\"\\n\")\n",
    "\n",
    "train_en_X = []\n",
    "train_fr_X = []\n",
    "train_fr_Y = []\n",
    "\n",
    "en_max_len = 0\n",
    "fr_max_len = 0\n",
    "\n",
    "vocab_size_en = sp_en.GetPieceSize() #-1\n",
    "vocab_size_fr = sp_fr.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'bert' has no attribute 'bert_tokenization'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-dc5d770e9849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Bert Tokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mBertTokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert_tokenization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFullTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbert_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvocabulary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolved_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masset_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mto_lower_case\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolved_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'bert' has no attribute 'bert_tokenization'"
     ]
    }
   ],
   "source": [
    "# Bert Tokenizer\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_bert(text):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "\n",
    "# source_tokenizer = [tokenize_bert(ele) for ele in source]\n",
    "# source_tensor = source_tokenizer\n",
    "# print(source_tokenizer[0])\n",
    "\n",
    "# target_tokenizer = [tokenize_bert(ele) for ele in target]\n",
    "# target_tensor = target_tokenizer\n",
    "# print(target_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(source_tensor, target_tensor, test_size=0.2, random_state=0)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "\n",
    "# Show length\n",
    "# print(len(X_train), len(y_train), len(X_val), len(y_val))\n",
    "# type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the source and target tokens and post pad them\n",
    "# Assuming three extra tokens: <end>: #vocab_size_en | #vocab_size_fr,\n",
    "# <empty>: #vocab_size_en+1 | #vocab_size_fr+1, and <start>: #vocab_size_fr+2\n",
    "\n",
    "end_token_id_en = vocab_size_en\n",
    "empty_token_id_en = vocab_size_en + 1\n",
    "end_token_id_fr = vocab_size_fr\n",
    "empty_token_id_fr = vocab_size_fr + 1\n",
    "start_token_id_fr = vocab_size_fr + 2\n",
    "\n",
    "# The input text only needs two extra tokens while the output needs 3\n",
    "vocab_size_en = vocab_size_en + 2\n",
    "vocab_size_fr = vocab_size_fr + 3\n",
    "\n",
    "\n",
    "for i in range(len(en_text)):\n",
    "  en_seq = sp_en.EncodeAsIds(en_text[i].strip()) + [end_token_id_en]\n",
    "  en_max_len = max(en_max_len, len(en_seq))\n",
    "  train_en_X.append(en_seq)\n",
    "\n",
    "  fr_seq = sp_fr.EncodeAsIds(fr_text[i].strip()) + [end_token_id_fr]\n",
    "  fr_max_len = max(fr_max_len, len(fr_seq))\n",
    "  train_fr_X.append(fr_seq)\n",
    "\n",
    "# Cleaning up the memory, work with subword\n",
    "en_text = []\n",
    "fr_text = []\n",
    "\n",
    "# Padding all the samples with <empty> token to make them all of the same length\n",
    "# equal to the longest one\n",
    "train_en_X = pad_sequences(train_en_X, maxlen=en_max_len,\n",
    "                           padding=\"post\", value=empty_token_id_en)\n",
    "# maxlen is fr_max_len+1 since we need to accomodate for <start>\n",
    "train_fr_X = pad_sequences(train_fr_X, maxlen=fr_max_len+1,\n",
    "                           padding=\"post\", value=empty_token_id_fr)\n",
    "\n",
    "# Converting the train_fr_Y to a one-hot vector needed by the training phase as\n",
    "# the output\n",
    "train_fr_Y = to_categorical(train_fr_X, num_classes=vocab_size_fr)\n",
    "\n",
    "# Moving the last <empty> to the first position in each input sample\n",
    "train_fr_X = np.roll(train_fr_X, 1, axis=-1)\n",
    "# Changing the first token in each input sample to <start>\n",
    "train_fr_X[:, 0] = start_token_id_fr\n",
    "\n",
    "fr_max_len = fr_max_len + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Input Language; index to word mapping\")\n",
    "# util.convert(source_tokenizer, X_train[0])\n",
    "# print ()\n",
    "# print (\"Target Language; index to word mapping\")\n",
    "# util.convert(target_tokenizer, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder input (English)\n",
    "hidden_dim = 128\n",
    "input_en = Input(batch_shape=(None, en_max_len), name='input_en')\n",
    "\n",
    "# English embedding layer\n",
    "embedding_en = layers.Embedding(vocab_size_en, hidden_dim, name='embedding_en')\n",
    "embedded_en = embedding_en(input_en)\n",
    "\n",
    "# Encoder RNN (LSTM) layer\n",
    "encoder_lstm = layers.Bidirectional(\n",
    "                  layers.LSTM(hidden_dim,\n",
    "                              return_sequences=True, return_state=True),\n",
    "                  name=\"encoder_lstm\")\n",
    "(encoded_en,\n",
    "  forward_h_en, forward_c_en,\n",
    "  backward_h_en, backward_c_en) = encoder_lstm(embedded_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder input (French)\n",
    "input_fr = Input(batch_shape=(None, None), name='input_fr')\n",
    "\n",
    "# English embedding layer\n",
    "embedding_fr = layers.Embedding(vocab_size_fr, hidden_dim, name='embedding_fr')\n",
    "embedded_fr = embedding_fr(input_fr)\n",
    "\n",
    "state_h_en = layers.concatenate([forward_h_en, backward_h_en])\n",
    "state_c_en = layers.concatenate([forward_c_en, backward_c_en])\n",
    "\n",
    "# Decoder RNN (LSTM) layer\n",
    "decoder_lstm = layers.LSTM(hidden_dim * 2, return_sequences=True,\n",
    "                           return_state=True, name=\"decoder_lstm\")\n",
    "(encoded_fr,\n",
    "  forward_h_fr, forward_c_fr) = decoder_lstm(embedded_fr,\n",
    "                 initial_state=[state_h_en, state_c_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention layer\n",
    "attention_layer = attention.AttentionLayer(name='attention_layer')\n",
    "attention_out, attention_states = attention_layer({\"values\": encoded_en,\n",
    "                                                   \"query\": encoded_fr})\n",
    "\n",
    "# Concatenating the decoder output with attention output\n",
    "rnn_output = layers.concatenate([encoded_fr, attention_out], name=\"rnn_output\")\n",
    "\n",
    "# Dense layer\n",
    "dense_layer0 = layers.Dense(2048, activation='relu', name='dense_0')\n",
    "dl0 = dense_layer0(rnn_output)\n",
    "\n",
    "dense_layer1 = layers.Dense(1024, activation='relu', name='dense_1')\n",
    "dl1 = dense_layer1(dl0)\n",
    "\n",
    "dense_layer2 = layers.Dense(512, activation='relu', name='dense_2')\n",
    "dl2 = dense_layer2(dl1)\n",
    "\n",
    "dl2 = layers.Dropout(0.4)(dl2)\n",
    "\n",
    "dense_layer3 = layers.Dense(vocab_size_fr, activation='softmax', name='dense_3')\n",
    "dense_output = dense_layer3(dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_en (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_en (Embedding)        (None, 50, 128)      44672       input_en[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_fr (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (Bidirectional)    [(None, 50, 256), (N 263168      embedding_en[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_fr (Embedding)        (None, None, 128)    65024       input_fr[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][3]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256)          0           encoder_lstm[0][2]               \n",
      "                                                                 encoder_lstm[0][4]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  394240      embedding_fr[0][0]               \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      decoder_lstm[0][0]               \n",
      "                                                                 encoder_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "rnn_output (Concatenate)        (None, None, 512)    0           decoder_lstm[0][0]               \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, None, 2048)   1050624     rnn_output[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 1024)   2098176     dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 512)    524800      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 512)    0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 508)    260604      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,832,636\n",
      "Trainable params: 4,832,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_en (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_en (Embedding)        (None, 50, 128)      44672       input_en[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (Bidirectional)    [(None, 50, 256), (N 263168      embedding_en[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][3]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256)          0           encoder_lstm[0][2]               \n",
      "                                                                 encoder_lstm[0][4]               \n",
      "==================================================================================================\n",
      "Total params: 307,840\n",
      "Trainable params: 307,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_fr (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_fr (Embedding)        (None, None, 128)    65024       input_fr[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_h (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_c (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  394240      embedding_fr[0][0]               \n",
      "                                                                 input_h[0][0]                    \n",
      "                                                                 input_c[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_encoded_en (InputLayer)   [(None, 50, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      decoder_lstm[1][0]               \n",
      "                                                                 input_encoded_en[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "generative_output (Concatenate) (None, None, 512)    0           decoder_lstm[1][0]               \n",
      "                                                                 attention_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, None, 2048)   1050624     generative_output[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 1024)   2098176     dense_0[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 512)    524800      dense_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 508)    260604      dense_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,524,796\n",
      "Trainable params: 4,524,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "training_model = models.Model([input_en, input_fr], dense_output)\n",
    "training_model.summary()\n",
    "\n",
    "training_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=[model.MaskedCategoricalAccuracy(empty_token_id_fr),\n",
    "                                model.ExactMatchedAccuracy(empty_token_id_fr)])\n",
    "\n",
    "# Generative models\n",
    "encoder_model = models.Model([input_en],\n",
    "                             [encoded_en,\n",
    "                              state_h_en, state_c_en])\n",
    "encoder_model.summary()\n",
    "\n",
    "\n",
    "# The decoder model, to generate the French tokens (in integer form)\n",
    "input_h = layers.Input(batch_shape=(None, hidden_dim * 2),\n",
    "                       name='input_h')\n",
    "input_c = layers.Input(batch_shape=(None, hidden_dim * 2),\n",
    "                       name='input_c')\n",
    "\n",
    "(decoder_output,\n",
    "  output_h,\n",
    "  output_c) = decoder_lstm(embedded_fr,\n",
    "                           initial_state=[input_h, input_c])\n",
    "\n",
    "input_encoded_en = layers.Input(batch_shape=(None, en_max_len, hidden_dim * 2),\n",
    "                                name='input_encoded_en')\n",
    "\n",
    "attention_out, attention_state = attention_layer({\"values\": input_encoded_en,\n",
    "                                                  \"query\": decoder_output})\n",
    "\n",
    "generative_output = layers.concatenate([decoder_output,\n",
    "                                        attention_out],\n",
    "                                       name=\"generative_output\")\n",
    "\n",
    "g0 = dense_layer0(generative_output)\n",
    "g1 = dense_layer1(g0)\n",
    "g2 = dense_layer2(g1)\n",
    "dense_output = dense_layer3(g2)\n",
    "\n",
    "decoder_model = models.Model([input_encoded_en, input_fr,\n",
    "                              input_h, input_c],\n",
    "                             [dense_output, attention_state,\n",
    "                              output_h, output_c])\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_accuracy: 0.7061\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1260s 10s/step - loss: 0.0308 - masked_categorical_accuracy: 0.9814 - exact_matched_accuracy: 0.6481 - val_loss: 0.0214 - val_masked_categorical_accuracy: 0.9871 - val_exact_matched_accuracy: 0.7332\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1252s 10s/step - loss: 0.0271 - masked_categorical_accuracy: 0.9834 - exact_matched_accuracy: 0.6769 - val_loss: 0.0195 - val_masked_categorical_accuracy: 0.9881 - val_exact_matched_accuracy: 0.7491\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1261s 10s/step - loss: 0.0238 - masked_categorical_accuracy: 0.9851 - exact_matched_accuracy: 0.7002 - val_loss: 0.0176 - val_masked_categorical_accuracy: 0.9890 - val_exact_matched_accuracy: 0.7680\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1262s 10s/step - loss: 0.0209 - masked_categorical_accuracy: 0.9869 - exact_matched_accuracy: 0.7311 - val_loss: 0.0173 - val_masked_categorical_accuracy: 0.9894 - val_exact_matched_accuracy: 0.7710\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1254s 10s/step - loss: 0.0202 - masked_categorical_accuracy: 0.9873 - exact_matched_accuracy: 0.7387 - val_loss: 0.0145 - val_masked_categorical_accuracy: 0.9911 - val_exact_matched_accuracy: 0.8051\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 1260s 10s/step - loss: 0.0180 - masked_categorical_accuracy: 0.9888 - exact_matched_accuracy: 0.7669 - val_loss: 0.0140 - val_masked_categorical_accuracy: 0.9916 - val_exact_matched_accuracy: 0.8138\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1252s 10s/step - loss: 0.0162 - masked_categorical_accuracy: 0.9899 - exact_matched_accuracy: 0.7830 - val_loss: 0.0126 - val_masked_categorical_accuracy: 0.9923 - val_exact_matched_accuracy: 0.8291\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1273s 10s/step - loss: 0.0149 - masked_categorical_accuracy: 0.9907 - exact_matched_accuracy: 0.7987 - val_loss: 0.0112 - val_masked_categorical_accuracy: 0.9934 - val_exact_matched_accuracy: 0.8545\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 1263s 10s/step - loss: 0.0138 - masked_categorical_accuracy: 0.9912 - exact_matched_accuracy: 0.8087 - val_loss: 0.0107 - val_masked_categorical_accuracy: 0.9935 - val_exact_matched_accuracy: 0.8547\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1256s 10s/step - loss: 0.0131 - masked_categorical_accuracy: 0.9917 - exact_matched_accuracy: 0.8175 - val_loss: 0.0100 - val_masked_categorical_accuracy: 0.9940 - val_exact_matched_accuracy: 0.8648\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1253s 10s/step - loss: 0.0124 - masked_categorical_accuracy: 0.9923 - exact_matched_accuracy: 0.8298 - val_loss: 0.0099 - val_masked_categorical_accuracy: 0.9941 - val_exact_matched_accuracy: 0.8687\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 1256s 10s/step - loss: 0.0120 - masked_categorical_accuracy: 0.9924 - exact_matched_accuracy: 0.8317 - val_loss: 0.0098 - val_masked_categorical_accuracy: 0.9942 - val_exact_matched_accuracy: 0.8678\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1276s 10s/step - loss: 0.0113 - masked_categorical_accuracy: 0.9928 - exact_matched_accuracy: 0.8390 - val_loss: 0.0094 - val_masked_categorical_accuracy: 0.9943 - val_exact_matched_accuracy: 0.8682\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1260s 10s/step - loss: 0.0106 - masked_categorical_accuracy: 0.9933 - exact_matched_accuracy: 0.8479 - val_loss: 0.0091 - val_masked_categorical_accuracy: 0.9946 - val_exact_matched_accuracy: 0.8753\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 1256s 10s/step - loss: 0.0101 - masked_categorical_accuracy: 0.9936 - exact_matched_accuracy: 0.8531 - val_loss: 0.0087 - val_masked_categorical_accuracy: 0.9947 - val_exact_matched_accuracy: 0.8768\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 1252s 10s/step - loss: 0.0095 - masked_categorical_accuracy: 0.9939 - exact_matched_accuracy: 0.8591 - val_loss: 0.0084 - val_masked_categorical_accuracy: 0.9951 - val_exact_matched_accuracy: 0.8885\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 1265s 10s/step - loss: 0.0089 - masked_categorical_accuracy: 0.9943 - exact_matched_accuracy: 0.8675 - val_loss: 0.0082 - val_masked_categorical_accuracy: 0.9954 - val_exact_matched_accuracy: 0.8926\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 1264s 10s/step - loss: 0.0088 - masked_categorical_accuracy: 0.9944 - exact_matched_accuracy: 0.8700 - val_loss: 0.0076 - val_masked_categorical_accuracy: 0.9956 - val_exact_matched_accuracy: 0.8971\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 1266s 10s/step - loss: 0.0081 - masked_categorical_accuracy: 0.9947 - exact_matched_accuracy: 0.8762 - val_loss: 0.0073 - val_masked_categorical_accuracy: 0.9958 - val_exact_matched_accuracy: 0.9027\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 1256s 10s/step - loss: 0.0081 - masked_categorical_accuracy: 0.9947 - exact_matched_accuracy: 0.8757 - val_loss: 0.0077 - val_masked_categorical_accuracy: 0.9955 - val_exact_matched_accuracy: 0.8943\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 1258s 10s/step - loss: 0.0079 - masked_categorical_accuracy: 0.9949 - exact_matched_accuracy: 0.8807 - val_loss: 0.0074 - val_masked_categorical_accuracy: 0.9957 - val_exact_matched_accuracy: 0.8996\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 1257s 10s/step - loss: 0.0075 - masked_categorical_accuracy: 0.9952 - exact_matched_accuracy: 0.8855 - val_loss: 0.0069 - val_masked_categorical_accuracy: 0.9962 - val_exact_matched_accuracy: 0.9097\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 1265s 10s/step - loss: 0.0069 - masked_categorical_accuracy: 0.9955 - exact_matched_accuracy: 0.8929 - val_loss: 0.0070 - val_masked_categorical_accuracy: 0.9960 - val_exact_matched_accuracy: 0.9050\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 1269s 10s/step - loss: 0.0068 - masked_categorical_accuracy: 0.9956 - exact_matched_accuracy: 0.8939 - val_loss: 0.0069 - val_masked_categorical_accuracy: 0.9960 - val_exact_matched_accuracy: 0.9050\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 1277s 10s/step - loss: 0.0069 - masked_categorical_accuracy: 0.9955 - exact_matched_accuracy: 0.8924 - val_loss: 0.0064 - val_masked_categorical_accuracy: 0.9964 - val_exact_matched_accuracy: 0.9126\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 31578s 259s/step - loss: 0.0064 - masked_categorical_accuracy: 0.9958 - exact_matched_accuracy: 0.8977 - val_loss: 0.0062 - val_masked_categorical_accuracy: 0.9965 - val_exact_matched_accuracy: 0.9170\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 1782s 14s/step - loss: 0.0060 - masked_categorical_accuracy: 0.9962 - exact_matched_accuracy: 0.9071 - val_loss: 0.0065 - val_masked_categorical_accuracy: 0.9963 - val_exact_matched_accuracy: 0.9106\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 4457s 36s/step - loss: 0.0059 - masked_categorical_accuracy: 0.9962 - exact_matched_accuracy: 0.9064 - val_loss: 0.0064 - val_masked_categorical_accuracy: 0.9963 - val_exact_matched_accuracy: 0.9127\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 2150s 10s/step - loss: 0.0060 - masked_categorical_accuracy: 0.9961 - exact_matched_accuracy: 0.9048 - val_loss: 0.0061 - val_masked_categorical_accuracy: 0.9966 - val_exact_matched_accuracy: 0.9192\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 1280s 10s/step - loss: 0.0053 - masked_categorical_accuracy: 0.9965 - exact_matched_accuracy: 0.9146 - val_loss: 0.0061 - val_masked_categorical_accuracy: 0.9966 - val_exact_matched_accuracy: 0.9176\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 1297s 11s/step - loss: 0.0054 - masked_categorical_accuracy: 0.9964 - exact_matched_accuracy: 0.9109 - val_loss: 0.0059 - val_masked_categorical_accuracy: 0.9968 - val_exact_matched_accuracy: 0.9228\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 1270s 10s/step - loss: 0.0053 - masked_categorical_accuracy: 0.9965 - exact_matched_accuracy: 0.9135 - val_loss: 0.0062 - val_masked_categorical_accuracy: 0.9966 - val_exact_matched_accuracy: 0.9176\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 1272s 10s/step - loss: 0.0054 - masked_categorical_accuracy: 0.9965 - exact_matched_accuracy: 0.9131 - val_loss: 0.0059 - val_masked_categorical_accuracy: 0.9968 - val_exact_matched_accuracy: 0.9239\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 4288s 35s/step - loss: 0.0052 - masked_categorical_accuracy: 0.9966 - exact_matched_accuracy: 0.9145 - val_loss: 0.0057 - val_masked_categorical_accuracy: 0.9970 - val_exact_matched_accuracy: 0.9268\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 1262s 10s/step - loss: 0.0049 - masked_categorical_accuracy: 0.9968 - exact_matched_accuracy: 0.9193 - val_loss: 0.0055 - val_masked_categorical_accuracy: 0.9970 - val_exact_matched_accuracy: 0.9285\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 1260s 10s/step - loss: 0.0049 - masked_categorical_accuracy: 0.9968 - exact_matched_accuracy: 0.9200 - val_loss: 0.0053 - val_masked_categorical_accuracy: 0.9971 - val_exact_matched_accuracy: 0.9312\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 1297s 11s/step - loss: 0.0044 - masked_categorical_accuracy: 0.9971 - exact_matched_accuracy: 0.9271 - val_loss: 0.0055 - val_masked_categorical_accuracy: 0.9971 - val_exact_matched_accuracy: 0.9284\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 1287s 10s/step - loss: 0.0046 - masked_categorical_accuracy: 0.9970 - exact_matched_accuracy: 0.9254 - val_loss: 0.0056 - val_masked_categorical_accuracy: 0.9969 - val_exact_matched_accuracy: 0.9233\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 1265s 10s/step - loss: 0.0043 - masked_categorical_accuracy: 0.9971 - exact_matched_accuracy: 0.9282 - val_loss: 0.0053 - val_masked_categorical_accuracy: 0.9973 - val_exact_matched_accuracy: 0.9337\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 1258s 10s/step - loss: 0.0041 - masked_categorical_accuracy: 0.9972 - exact_matched_accuracy: 0.9309 - val_loss: 0.0052 - val_masked_categorical_accuracy: 0.9972 - val_exact_matched_accuracy: 0.9317\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 1258s 10s/step - loss: 0.0039 - masked_categorical_accuracy: 0.9974 - exact_matched_accuracy: 0.9343 - val_loss: 0.0054 - val_masked_categorical_accuracy: 0.9972 - val_exact_matched_accuracy: 0.9316\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 1264s 10s/step - loss: 0.0041 - masked_categorical_accuracy: 0.9973 - exact_matched_accuracy: 0.9326 - val_loss: 0.0053 - val_masked_categorical_accuracy: 0.9973 - val_exact_matched_accuracy: 0.9348\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 1259s 10s/step - loss: 0.0039 - masked_categorical_accuracy: 0.9974 - exact_matched_accuracy: 0.9342 - val_loss: 0.0052 - val_masked_categorical_accuracy: 0.9973 - val_exact_matched_accuracy: 0.9344\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 1253s 10s/step - loss: 0.0038 - masked_categorical_accuracy: 0.9975 - exact_matched_accuracy: 0.9364 - val_loss: 0.0054 - val_masked_categorical_accuracy: 0.9972 - val_exact_matched_accuracy: 0.9296\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 1252s 10s/step - loss: 0.0037 - masked_categorical_accuracy: 0.9975 - exact_matched_accuracy: 0.9366 - val_loss: 0.0050 - val_masked_categorical_accuracy: 0.9974 - val_exact_matched_accuracy: 0.9358\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 1262s 10s/step - loss: 0.0036 - masked_categorical_accuracy: 0.9976 - exact_matched_accuracy: 0.9387 - val_loss: 0.0049 - val_masked_categorical_accuracy: 0.9976 - val_exact_matched_accuracy: 0.9427\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 1257s 10s/step - loss: 0.0035 - masked_categorical_accuracy: 0.9977 - exact_matched_accuracy: 0.9404 - val_loss: 0.0053 - val_masked_categorical_accuracy: 0.9973 - val_exact_matched_accuracy: 0.9352\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 1249s 10s/step - loss: 0.0036 - masked_categorical_accuracy: 0.9976 - exact_matched_accuracy: 0.9378 - val_loss: 0.0051 - val_masked_categorical_accuracy: 0.9975 - val_exact_matched_accuracy: 0.9390\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 1249s 10s/step - loss: 0.0034 - masked_categorical_accuracy: 0.9977 - exact_matched_accuracy: 0.9412 - val_loss: 0.0049 - val_masked_categorical_accuracy: 0.9975 - val_exact_matched_accuracy: 0.9398\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 1248s 10s/step - loss: 0.0033 - masked_categorical_accuracy: 0.9978 - exact_matched_accuracy: 0.9431 - val_loss: 0.0053 - val_masked_categorical_accuracy: 0.9973 - val_exact_matched_accuracy: 0.9354\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 1249s 10s/step - loss: 0.0032 - masked_categorical_accuracy: 0.9979 - exact_matched_accuracy: 0.9466 - val_loss: 0.0048 - val_masked_categorical_accuracy: 0.9977 - val_exact_matched_accuracy: 0.9453\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 1258s 10s/step - loss: 0.0030 - masked_categorical_accuracy: 0.9980 - exact_matched_accuracy: 0.9473 - val_loss: 0.0052 - val_masked_categorical_accuracy: 0.9974 - val_exact_matched_accuracy: 0.9377\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 1264s 10s/step - loss: 0.0034 - masked_categorical_accuracy: 0.9977 - exact_matched_accuracy: 0.9414 - val_loss: 0.0048 - val_masked_categorical_accuracy: 0.9976 - val_exact_matched_accuracy: 0.9415\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 1262s 10s/step - loss: 0.0040 - masked_categorical_accuracy: 0.9978 - exact_matched_accuracy: 0.9488 - val_loss: 0.8009 - val_masked_categorical_accuracy: 0.7006 - val_exact_matched_accuracy: 6.7214e-04\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 1250s 10s/step - loss: 0.1723 - masked_categorical_accuracy: 0.9093 - exact_matched_accuracy: 0.4154 - val_loss: 0.0079 - val_masked_categorical_accuracy: 0.9952 - val_exact_matched_accuracy: 0.8884\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 1251s 10s/step - loss: 0.0085 - masked_categorical_accuracy: 0.9946 - exact_matched_accuracy: 0.8751 - val_loss: 0.0056 - val_masked_categorical_accuracy: 0.9969 - val_exact_matched_accuracy: 0.9252\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 1248s 10s/step - loss: 0.0054 - masked_categorical_accuracy: 0.9965 - exact_matched_accuracy: 0.9153 - val_loss: 0.0049 - val_masked_categorical_accuracy: 0.9974 - val_exact_matched_accuracy: 0.9371\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 1247s 10s/step - loss: 0.0042 - masked_categorical_accuracy: 0.9973 - exact_matched_accuracy: 0.9329 - val_loss: 0.0045 - val_masked_categorical_accuracy: 0.9977 - val_exact_matched_accuracy: 0.9448\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 1246s 10s/step - loss: 0.0036 - masked_categorical_accuracy: 0.9977 - exact_matched_accuracy: 0.9418 - val_loss: 0.0043 - val_masked_categorical_accuracy: 0.9978 - val_exact_matched_accuracy: 0.9467\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 1260s 10s/step - loss: 0.0032 - masked_categorical_accuracy: 0.9979 - exact_matched_accuracy: 0.9460 - val_loss: 0.0041 - val_masked_categorical_accuracy: 0.9979 - val_exact_matched_accuracy: 0.9492\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 1251s 10s/step - loss: 0.0028 - masked_categorical_accuracy: 0.9982 - exact_matched_accuracy: 0.9536 - val_loss: 0.0041 - val_masked_categorical_accuracy: 0.9979 - val_exact_matched_accuracy: 0.9507\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 32764s 268s/step - loss: 0.0026 - masked_categorical_accuracy: 0.9982 - exact_matched_accuracy: 0.9537 - val_loss: 0.0042 - val_masked_categorical_accuracy: 0.9979 - val_exact_matched_accuracy: 0.9491\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 1252s 10s/step - loss: 0.0024 - masked_categorical_accuracy: 0.9983 - exact_matched_accuracy: 0.9567 - val_loss: 0.0041 - val_masked_categorical_accuracy: 0.9980 - val_exact_matched_accuracy: 0.9519\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 1278s 10s/step - loss: 0.0023 - masked_categorical_accuracy: 0.9985 - exact_matched_accuracy: 0.9608 - val_loss: 0.0040 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9529\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 1258s 10s/step - loss: 0.0022 - masked_categorical_accuracy: 0.9985 - exact_matched_accuracy: 0.9617 - val_loss: 0.0040 - val_masked_categorical_accuracy: 0.9980 - val_exact_matched_accuracy: 0.9528\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 1246s 10s/step - loss: 0.0021 - masked_categorical_accuracy: 0.9986 - exact_matched_accuracy: 0.9635 - val_loss: 0.0043 - val_masked_categorical_accuracy: 0.9980 - val_exact_matched_accuracy: 0.9518\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 1246s 10s/step - loss: 0.0021 - masked_categorical_accuracy: 0.9986 - exact_matched_accuracy: 0.9636 - val_loss: 0.0042 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9544\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 1248s 10s/step - loss: 0.0019 - masked_categorical_accuracy: 0.9988 - exact_matched_accuracy: 0.9672 - val_loss: 0.0041 - val_masked_categorical_accuracy: 0.9982 - val_exact_matched_accuracy: 0.9563\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 1247s 10s/step - loss: 0.0019 - masked_categorical_accuracy: 0.9987 - exact_matched_accuracy: 0.9662 - val_loss: 0.0042 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9550\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 1254s 10s/step - loss: 0.0018 - masked_categorical_accuracy: 0.9987 - exact_matched_accuracy: 0.9671 - val_loss: 0.0042 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9546\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 1254s 10s/step - loss: 0.0018 - masked_categorical_accuracy: 0.9988 - exact_matched_accuracy: 0.9673 - val_loss: 0.0044 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9528\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 1245s 10s/step - loss: 0.0018 - masked_categorical_accuracy: 0.9988 - exact_matched_accuracy: 0.9673 - val_loss: 0.0041 - val_masked_categorical_accuracy: 0.9982 - val_exact_matched_accuracy: 0.9566\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 1247s 10s/step - loss: 0.0017 - masked_categorical_accuracy: 0.9988 - exact_matched_accuracy: 0.9687 - val_loss: 0.0042 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9553\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 1249s 10s/step - loss: 0.0017 - masked_categorical_accuracy: 0.9988 - exact_matched_accuracy: 0.9688 - val_loss: 0.0045 - val_masked_categorical_accuracy: 0.9980 - val_exact_matched_accuracy: 0.9527\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 1307s 11s/step - loss: 0.0018 - masked_categorical_accuracy: 0.9988 - exact_matched_accuracy: 0.9681 - val_loss: 0.0044 - val_masked_categorical_accuracy: 0.9982 - val_exact_matched_accuracy: 0.9568\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 1294s 11s/step - loss: 0.0016 - masked_categorical_accuracy: 0.9989 - exact_matched_accuracy: 0.9706 - val_loss: 0.0044 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9544\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 1278s 10s/step - loss: 0.0017 - masked_categorical_accuracy: 0.9989 - exact_matched_accuracy: 0.9703 - val_loss: 0.0044 - val_masked_categorical_accuracy: 0.9980 - val_exact_matched_accuracy: 0.9523\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 1289s 10s/step - loss: 0.0017 - masked_categorical_accuracy: 0.9988 - exact_matched_accuracy: 0.9693 - val_loss: 0.0044 - val_masked_categorical_accuracy: 0.9981 - val_exact_matched_accuracy: 0.9546\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00087: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "checkpoint_dir = 'save'\n",
    "\n",
    "pocket = EarlyStopping(monitor='val_exact_matched_accuracy', min_delta=0.001,\n",
    "                       patience=10, verbose=1, mode='max',\n",
    "                       restore_best_weights = True)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    history = training_model.fit(x=[train_en_X, train_fr_X], y=train_fr_Y, batch_size=786,\n",
    "                             epochs=100, verbose=1, validation_split=0.3, shuffle=True,\n",
    "                             workers=5, use_multiprocessing=True, callbacks=[pocket])\n",
    "\n",
    "training_model.save_weights(os.path.join(checkpoint_dir, \"nmt.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'save'\n",
    "#training_model.save_weights(os.path.join(checkpoint_dir, \"nmt.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring the latest checkpoint in checkpoint_dir\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "training_model.load_weights(os.path.join(checkpoint_dir, \"nmt.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "176/176 [==============================] - 599s 3s/step - loss: 0.0013 - masked_categorical_accuracy: 0.9991 - exact_matched_accuracy: 0.9767\n",
      "Test loss: 0.0020254049450159073\n",
      "Test masked categorical accuracy: 0.9988803863525391\n",
      "Test exact matched accuracy: 0.9716096520423889\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "#util.plot_training(history)\n",
    "\n",
    "results = training_model.evaluate(x=[train_en_X, train_fr_X], y=train_fr_Y,\n",
    "                                  batch_size=786, verbose=1,\n",
    "                                  workers=1, use_multiprocessing=False)\n",
    "\n",
    "print('Test loss:', results[0])\n",
    "print('Test masked categorical accuracy:', results[1])\n",
    "print('Test exact matched accuracy:', results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The input English string:  the united states is never freezing during november , but the united states is sometimes rainy in winter .\nThe output French string:  les états-unis ne sont jamais glaciales en novembre , mais il est parfois pluvieux en hiver .\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# The input English string\n",
    "english_string = \"the united states is never freezing during november , but the united states is sometimes rainy in winter .\"\n",
    "\n",
    "# First, let's tokenize the Eglish string, then pad it\n",
    "english_tokens = sp_en.EncodeAsIds(english_string.strip()) + [end_token_id_en]\n",
    "english_tokens = pad_sequences([english_tokens], maxlen=en_max_len,\n",
    "                               padding=\"post\", value=empty_token_id_en)\n",
    "\n",
    "# The encoder, we only need to use it once per each English string\n",
    "(encoded_en_test,\n",
    "  state_h_en_test, state_c_en_test) = encoder_model.predict(english_tokens)\n",
    "\n",
    "# In order to find a better translation, we are using Beam search\n",
    "beam_search_list = [{\n",
    "  \"decoder_input\": {\n",
    "    \"input_encoded_en\": encoded_en_test,\n",
    "    \"input_fr\": np.array([[start_token_id_fr]]),\n",
    "    \"input_h\": state_h_en_test,\n",
    "    \"input_c\": state_c_en_test\n",
    "  },\n",
    "  \"score\": 0.0,\n",
    "  \"parent_node\": None,\n",
    "  \"depth\": 0,\n",
    "  \"attention_weights\": None,\n",
    "}]\n",
    "ended_branches = []\n",
    "\n",
    "beam_size = 10\n",
    "\n",
    "# We are generating up to fr_max_len tokens\n",
    "for i in range(fr_max_len):\n",
    "  new_beam_candidates = []\n",
    "  # Predict the next token for each member of the list\n",
    "  for beam in beam_search_list:\n",
    "    # Use the decoder to predict the next token using the previously\n",
    "    # predicted token\n",
    "    (output,\n",
    "      attention_out,\n",
    "      state_h_en_test,\n",
    "      state_c_en_test) = decoder_model.predict(beam[\"decoder_input\"])\n",
    "    # Find the top beam_size candidates\n",
    "    top_k = np.argpartition(output[0, 0, :], -beam_size)[-beam_size:]\n",
    "    # For each candidate, put it in the list to predict the next token for it\n",
    "    for k in top_k:\n",
    "      if output[0, 0, k].item() > 0.0:\n",
    "        log_k = math.log(output[0, 0, k].item())\n",
    "      else:\n",
    "        log_k = -sys.float_info.max\n",
    "\n",
    "      if k == end_token_id_fr:\n",
    "        ended_branches.append({\n",
    "          \"decoder_input\": {\n",
    "            \"input_encoded_en\": encoded_en_test,\n",
    "            \"input_fr\": np.array([[k]]),\n",
    "            \"input_h\": state_h_en_test,\n",
    "            \"input_c\": state_c_en_test,\n",
    "          },\n",
    "          \"score\": beam[\"score\"] + log_k,\n",
    "          \"parent_node\": beam,\n",
    "          \"depth\": beam[\"depth\"] + 1,\n",
    "          \"attention_weights\": attention_out,\n",
    "        })\n",
    "      else:\n",
    "        new_beam_candidates.append({\n",
    "          \"decoder_input\": {\n",
    "            \"input_encoded_en\": encoded_en_test,\n",
    "            \"input_fr\": np.array([[k]]),\n",
    "            \"input_h\": state_h_en_test,\n",
    "            \"input_c\": state_c_en_test,\n",
    "          },\n",
    "          \"score\": beam[\"score\"] + log_k,\n",
    "          \"parent_node\": beam,\n",
    "          \"depth\": beam[\"depth\"] + 1,\n",
    "          \"attention_weights\": attention_out,\n",
    "        })\n",
    "\n",
    "  # Keeping only the top beam_size in the list\n",
    "  beam_search_list = sorted(new_beam_candidates,\n",
    "                            key=lambda b: b[\"score\"],\n",
    "                            reverse=True)[0:beam_size]\n",
    "\n",
    "# Now that we are done with our beam search, let's take the best score and\n",
    "# detokenize it\n",
    "beam_node = sorted(beam_search_list + ended_branches,\n",
    "                   key=lambda b: b[\"score\"] / b[\"depth\"],\n",
    "                   reverse=True)[0]\n",
    "\n",
    "# Trace the best beam back to the parent node\n",
    "all_french_tokens = []\n",
    "attention_weights = []\n",
    "while beam_node[\"parent_node\"] is not None:\n",
    "    all_french_tokens.append(\n",
    "        beam_node[\"decoder_input\"][\"input_fr\"][0, 0].item())\n",
    "    attention_weights.append(beam_node[\"attention_weights\"])\n",
    "    beam_node = beam_node[\"parent_node\"]\n",
    "\n",
    "# We traced from tail to head, so we need to reserve the order to have it the right way\n",
    "all_french_tokens.reverse()\n",
    "attention_weights.reverse()\n",
    "\n",
    "# If there's any token out of the vocab, exclude it. This includes `<end>`,\n",
    "# `<empty>`, and <start> tokens\n",
    "french_tokens = [t for t in all_french_tokens if t < sp_fr.get_piece_size()]\n",
    "\n",
    "# Voila!\n",
    "french_string = sp_fr.DecodeIds(french_tokens)\n",
    "\n",
    "print(\"The input English string: \", english_string)\n",
    "print(\"The output French string: \", french_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the alignment matrix\n",
    "attention_mat = []\n",
    "for attn in attention_weights:\n",
    "  attention_mat.append(attn.reshape(-1))\n",
    "\n",
    "# We want to have the English tokens on the left axis, so we need to\n",
    "# trasponse the matrix over the diagonal running from upper right to lower left\n",
    "attention_mat = np.flipud(np.transpose(np.flipud(attention_mat)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "ax.imshow(attention_mat)\n",
    "\n",
    "ax.set_xticks(np.arange(attention_mat.shape[1]))\n",
    "ax.set_yticks(np.arange(attention_mat.shape[0]))\n",
    "\n",
    "def map_en_special_tokens(t):\n",
    "    switcher = {}\n",
    "    switcher[end_token_id_en] = \"<end>\"\n",
    "    switcher[empty_token_id_en] = \"<empty>\"\n",
    "    return switcher.get(t, \"<unknown>\")\n",
    "\n",
    "def map_fr_special_tokens(t):\n",
    "    switcher = {}\n",
    "    switcher[end_token_id_fr] = \"<end>\"\n",
    "    switcher[empty_token_id_fr] = \"<empty>\"\n",
    "    switcher[start_token_id_fr] = \"<start>\"\n",
    "    return switcher.get(t, \"<unknown>\")\n",
    "\n",
    "ax.set_xticklabels([sp_fr.IdToPiece(t)\n",
    "                    if t < sp_fr.get_piece_size() else map_fr_special_tokens(t)\n",
    "                    for t in all_french_tokens])\n",
    "ax.set_yticklabels([sp_en.IdToPiece(t)\n",
    "                    if t < sp_en.get_piece_size() else map_en_special_tokens(t)\n",
    "                    for t in english_tokens[0].tolist()])\n",
    "\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# translate(u'I am going to work.')\n",
    "# translate(u'The project is super hard.')\n",
    "# util.translate(u'She works at home.', units, max_target_length, max_source_length, encoder, decoder, source_tokenizer, target_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Default GPU device: /device:GPU:0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "if not tf.test.gpu_device_name(): \n",
    "    warnings.warn('No GPU found')\n",
    "else: \n",
    "    print('Default GPU device: {}' .format(tf.test.gpu_device_name()))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)\n",
    "\n",
    "# Import all required libraries\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "# Split MNIST Train and Test data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Divide train set by 255\n",
    "x_train, x_test = x_train.astype(\"float32\") / 255, x_test.astype(\"float32\") / 255\n",
    "x_train, x_test = np.expand_dims(x_train, -1), np.expand_dims(x_test, -1)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train, y_test = keras.utils.to_categorical(y_train, num_classes=10), keras.utils.to_categorical(y_test, num_classes=10)\n",
    "# Build the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28,28,1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(1, 1)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "# Model summary and Evaluation\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "start = datetime.now()\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.1)\n",
    "stop = datetime.now()\n",
    "print(\"Time taken to execute:\" + str(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('tfgpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a75d68007abe45c64e50bc70737987651d46d0fb341f8ff51c4351246529ca1b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}